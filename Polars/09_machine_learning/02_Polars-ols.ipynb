{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a2fca58-ebb8-4395-8cbd-99882c7d8726",
   "metadata": {},
   "source": [
    "## Linear models with Polars-ols\n",
    "\n",
    "The Polars-ols plugin allows you to fit linear models using Polars expressions. You can install it (along with the `patsy` package for formulae) here\n",
    "\n",
    "### What are linear models?\n",
    "If you aren't familiar with linear models these are the classic fit-a-straight-line through the data. In a linear model we are trying to predict a target variable (referred to as `y` below) with one or more predictor variables (the `x`s below).\n",
    "\n",
    "Here is one (of many) simple introductions to linear models on youtube: https://www.youtube.com/watch?v=CtsRRUddV2s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32354a53-588f-471d-9b3e-edb61d998881",
   "metadata": {},
   "source": [
    "We begin by importing polars and polars_ols.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03873819-3831-4f55-9170-9f6be4b45518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import polars_ols as pls  \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909dc3b2-392c-4808-8944-29c28a95ad1c",
   "metadata": {},
   "source": [
    "Polars-ols is a Polars *plugin*. When we import a plugin the plugin registers its *namespace* with Polars. A namespace is a set of expressions that are gathered under a title. We have already met built-in namespaces such as `dt` for timeseries expressions or `str` for string expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aa0bf6-72ef-43e9-b6b0-3c48c9c6258e",
   "metadata": {},
   "source": [
    "We create a `DataFrame` with a some predictor columns `x1` and `x2`(the values of these columns are arbitrary). We create the target variable `y` as a linear sum of these columns with some random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9672f987-e04f-4696-992d-b16e682a0beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    pl.DataFrame(\n",
    "        {\n",
    "            \"x1\": [0.72, -2.43, -0.63, 0.05, -0.07, 0.65, -0.02, -1.64, -0.92, -0.27],\n",
    "            \"x2\": [0.24, 0.18, -0.95, 0.23, 0.44, 1.01, -2.08, -1.36, 0.01, 0.75],\n",
    "        }\n",
    "    )\n",
    "    .with_columns(\n",
    "        # Construct the target variable y with known coefficients of x1 and x2\n",
    "        # The linear model aims to find these coefficients\n",
    "        y = 2*pl.col(\"x1\") + 3*pl.col(\"x2\") + np.random.standard_normal(10)\n",
    "    )\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e93a83-b133-41d5-acc2-b86b6541a9cc",
   "metadata": {},
   "source": [
    "We can do a scatter plot showing the relationship of the target variable to a predictor variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b996f5-2835-4afe-a459-4e82f546c46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .plot\n",
    "    .scatter(\n",
    "        x=\"x1\",\n",
    "        y=\"y\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8b940d-f485-44d7-92bd-e8b8ba244afd",
   "metadata": {},
   "source": [
    "We start by fitting an ordinary least squares (i.e. vanilla linear regression) model. We specify:\n",
    "- the target column as `pl.col(\"y\")`\n",
    "- an ordinary least squares model with the `least_squares.ols` expression\n",
    "- the predictors as a list of expressions inside `least_squares.ols`\n",
    "- the name of the output column of predictions with `alias`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ea4b54-d49b-426e-9855-abc624c072da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_expr = (\n",
    "    pl.col(\"y\")\n",
    "    .least_squares.ols(\n",
    "        pl.col(\"x1\"), pl.col(\"x2\")\n",
    "    )\n",
    "    .alias(\"ols\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3446c833-998e-4f2f-8437-93f095d45cc1",
   "metadata": {},
   "source": [
    "We can then add a column with the predictions by passing the expression to `with_columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7a1a4b-c253-4a72-9c9c-5fe05deb7ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .with_columns(\n",
    "        ols_expr\n",
    "    )\n",
    ")       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c85aa45-5e48-48b7-b8bc-2daf2fa27a7c",
   "metadata": {},
   "source": [
    "### Coefficients\n",
    "If we want the regression coefficients instead of the predictions we can set the `mode` of the expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf40e67-68bd-445a-b8be-c3bdf1788df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_coeff_expr = (\n",
    "    pl.col(\"y\")\n",
    "    .least_squares.ols(\n",
    "        pl.col(\"x1\"), \n",
    "        pl.col(\"x2\"),\n",
    "        mode=\"coefficients\",\n",
    "        add_intercept=True\n",
    "    )\n",
    "    .alias(\"ols_intercept\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c9d1e0-ade6-46f5-aba6-0d2bdd7bb7db",
   "metadata": {},
   "source": [
    "We then get the coefficients as a `pl.Struct` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840c7e82-47ef-4c7a-8f0e-b402aaf072f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .select(\n",
    "        ols_coeff_expr\n",
    "    )\n",
    ")       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db58837-102e-49f2-a987-08362b37ed7a",
   "metadata": {},
   "source": [
    "The order here is `x1`, `x2`,`intercept`. We can get the variable names if we `unnest` the struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d499e3f-4831-4ecd-a3ce-170ab659be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    df\n",
    "    .select(\n",
    "        ols_coeff_expr\n",
    "    )\n",
    "    .unnest(\"ols_intercept\")\n",
    ")       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cd0077-edc4-46f7-884f-a1ae78d51cfe",
   "metadata": {},
   "source": [
    "Despite the noise and small dataset a linear model has done a decent job of finding coefficients for `x1` and `x2` that are close to those we specified when creating `y` above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b27f9d-f757-4ce9-bd1b-df45337dfebe",
   "metadata": {},
   "source": [
    "### Regularised regression\n",
    "\n",
    "For practical applications of linear regression we often want to apply regularisation to [damp the effect of noisy data](https://builtin.com/data-science/overfitting-regularization-python).\n",
    "\n",
    "We can do that in polars-ols with:\n",
    "- Lasso regression (that uses an L1 norm for the regularisation)\n",
    "- Ridge regression(that uses an L2 norm for the regularisation)\n",
    "- Elastic regression (that uses both L1 and L2 norms for the regularisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a862dfca-7077-4f7c-a7ac-8b60ae08318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_expr = pl.col(\"y\").least_squares.lasso(pl.col(\"x1\"), pl.col(\"x2\"), alpha=0.0001, add_intercept=True)\n",
    "ridge_expr = pl.col(\"y\").least_squares.ridge(pl.col(\"x1\"), pl.col(\"x2\"), alpha=0.0001, add_intercept=True)\n",
    "elastic_expr = pl.col(\"y\").least_squares.elastic_net(pl.col(\"x1\"), pl.col(\"x2\"), alpha=0.0001,l1_ratio=0.5, add_intercept=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989d98ba-eb70-4afb-bea3-92edf77c45d9",
   "metadata": {},
   "source": [
    "See the [Scikit-learn docs](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html) for the linear models with the same names for more background on the modelling method\n",
    "\n",
    "We now make predictions with these models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb4f0e8-a977-431c-8bb7-a0176dc0f15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .with_columns(\n",
    "        lasso_expr.round(3).alias(\"predictions_lasso\"),\n",
    "        ridge_expr.round(3).alias(\"predictions_ridge\"),\n",
    "        elastic_expr.round(3).alias(\"predictions_elastic\"),\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0415cb-d4d9-4fcc-83a0-85c550546cfd",
   "metadata": {},
   "source": [
    "> I've compared the results of the polars-ols Elastic Net model with the results from the Scikit-learn library in my production pipelines and they closely match.\n",
    "\n",
    "\n",
    "## Fitting models by groups\n",
    "We may want to fit a different model for different subgroups of the data. First we make a new `DataFrame` with a `groups` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9394d25-3d30-455e-88e7-1a179d8cbfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups = pl.DataFrame(\n",
    "    {\n",
    "        \"y\": [1.16, -2.16, -1.57, 0.21, 0.22, 1.6, -2.11, -2.92, -0.86, 0.47],\n",
    "        \"x1\": [0.72, -2.43, -0.63, 0.05, -0.07, 0.65, -0.02, -1.64, -0.92, -0.27],\n",
    "        \"x2\": [0.24, 0.18, -0.95, 0.23, 0.44, 1.01, -2.08, -1.36, 0.01, 0.75],\n",
    "        \"groups\":[0]*5 + [1]*5\n",
    "    }\n",
    ")\n",
    "df_groups.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3cda9b-6537-47fd-a942-83c1dbb2d3ae",
   "metadata": {},
   "source": [
    "We can then fit a separate linear model for each group using `over`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f432bff-5596-4de5-85b4-3f1617d7ffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_groups_expr = (\n",
    "    pl.col(\"y\")\n",
    "    .least_squares.ols(\n",
    "        pl.col(\"x1\"), \n",
    "        pl.col(\"x2\")\n",
    "    )\n",
    "    .over(\"groups\")\n",
    "    .alias(\"ols\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d372394-98e9-48fd-ab9e-a39ffeaf703a",
   "metadata": {},
   "source": [
    "We can again add a column of predictions by calling this expression in `with_columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7566b40-68f8-4371-938b-f42b633b375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_groups\n",
    "    .with_columns(\n",
    "        ols_groups_expr\n",
    "    )\n",
    ")       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0fa55b-4644-44a0-9743-ff7af1a8177d",
   "metadata": {},
   "source": [
    "## Making predictions on new data\n",
    "In the examples above we made predictions on the same data that we used to train the model. We see here how we can fit a model on one set of data and make predictions on another.\n",
    "\n",
    "First we need to fit a model to get the coefficients. We use the basic `ols` model again with `mode=\"coefficients\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4ff659-8d00-4bf1-b35a-489dfd1309e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_coef_expr = (\n",
    "    pl.col(\"y\")\n",
    "    .least_squares.ols(pl.col(\"x1\"), pl.col(\"x2\"), mode=\"coefficients\",add_intercept=True)\n",
    "    .alias(\"coef\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c56762-75df-4b18-a1c0-6746a960f3b4",
   "metadata": {},
   "source": [
    "We can use this to make a `DataFrame` of variable column names and coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01299fbe-9908-4f2e-8732-d954e17c6759",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .select(\n",
    "        ols_coef_expr\n",
    "    )\n",
    "    .unnest(\"coef\")\n",
    "    .unpivot()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4953fd3-f8e6-4ecb-9909-0816a87a9c50",
   "metadata": {},
   "source": [
    "Now we can make a class to fit the model and then make predictions on new data. The general flow is:\n",
    "- initialise the class with the model fit expression\n",
    "- fit the model in `fit` to get the coefficients\n",
    "- make predictions by:\n",
    "    - adding a row index to keep track of which row data came from\n",
    "    - piping the output to a function that joins the predictions\n",
    "    - in the join select the predictor columns along with the row index\n",
    "    - `unpivot` the predictor columns\n",
    "    - join the coefficients\n",
    "    - multiply the predictors by the coefficients\n",
    "    - `group_by` to gather the predictors back up into rows\n",
    "    - `agg` to get the sum of the predictors for the total prediction for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29418e4-2922-438a-ac3c-3c1e876c7a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class LinearRegressor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        target_col:str=\"y\",\n",
    "        feature_cols:List[str]=[\"x1\",\"x2\"],\n",
    "        model=\"ols\",\n",
    "        add_intercept:bool=False\n",
    "    ):\n",
    "        self.target_col = target_col\n",
    "        self.feature_cols = [pl.col(feature) for feature in feature_cols]\n",
    "        self.add_intercept = add_intercept\n",
    "        if model == \"ols\":\n",
    "            self.model_expr = (\n",
    "            pl.col(self.target_col)\n",
    "            .least_squares.ols(\n",
    "                *self.feature_cols,\n",
    "                mode=\"coefficients\",\n",
    "                add_intercept=self.add_intercept\n",
    "            )\n",
    "            .alias(\"coef\")\n",
    "        )\n",
    "\n",
    "    def fit(self, X):\n",
    "        # Fit the model and save the coefficients in a DataFrame\n",
    "        self.coefficients_df = (\n",
    "            X\n",
    "            .select(\n",
    "                self.model_expr\n",
    "            )\n",
    "            .unnest(\"coef\")\n",
    "        )\n",
    "        self.coef_ = (\n",
    "            self.coefficients_df\n",
    "            .select(self.feature_cols)\n",
    "            .unpivot()\n",
    "        )\n",
    "        if self.add_intercept:\n",
    "            self.intercept_ = self.coefficients_df[\"const\"][0]\n",
    "        else:\n",
    "            self.intercept_ = 0.0\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pl.DataFrame):\n",
    "        # Make predictions using the saved coefficients\n",
    "        return (\n",
    "            X\n",
    "            # Add a row index\n",
    "            .with_row_index()\n",
    "            .pipe(\n",
    "                # Join the predictions\n",
    "                lambda X: X.join(\n",
    "                    # Select the predictor columns\n",
    "                    X.select(\"index\", *self.feature_cols)\n",
    "                    # Unpivot (so we can join the coefficients)\n",
    "                    .unpivot(index=\"index\",value_name=\"predictor\")\n",
    "                    .join(\n",
    "                        # Join the coefficients\n",
    "                    (\n",
    "                        X\n",
    "                        .select(\n",
    "                            self.model_expr\n",
    "                        )\n",
    "                        .unnest(\"coef\")\n",
    "                        .unpivot(value_name=\"coef\")\n",
    "                    ),\n",
    "                        on=\"variable\",\n",
    "                    )\n",
    "                    # Multiply by the predictors\n",
    "                    .with_columns(pred=(pl.col(\"predictor\") * pl.col(\"coef\")))\n",
    "                    # Gather back up into rows\n",
    "                    .group_by(\"index\")\n",
    "                    .agg(\n",
    "                        pl.col(\"pred\").sum() + self.intercept_\n",
    "                    ),\n",
    "                    on=\"index\",\n",
    "                )\n",
    "            )\n",
    "            .sort(\"index\")\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a48d39d-7d66-471d-a46d-55f7c64c6d3e",
   "metadata": {},
   "source": [
    "Now we make train and test `DataFrames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ee90b5-5e22-44ab-ba3f-2b2daa985e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[:7]\n",
    "df_test = df[7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264066d2-5a2d-4bdf-8640-aa6672e4de47",
   "metadata": {},
   "source": [
    "We then: \n",
    "- instantiate the model\n",
    "- `fit` the model on `df_train`\n",
    "- make predictions on `df_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3e8831-e791-41ec-b873-a1828737d257",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regressor = LinearRegressor(target_col=\"y\",feature_cols=[\"x1\",\"x2\"],model=\"ols\")\n",
    "linear_regressor.fit(X=df_train)\n",
    "linear_regressor.transform(X=df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1236ae-2320-407b-8f71-83d98506baf4",
   "metadata": {},
   "source": [
    "See the repo page for more: https://github.com/azmyrajab/polars_ols/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8d5dd6-36f5-4670-862c-04143cfe83ef",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "We read the `load` and weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0afa649-ed56-44ad-ad09-38b372239a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_load_csv = \"../data/grid_load.csv\"\n",
    "weather_csv = \"../data/weather.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8981427a-d499-4ebd-b0de-af5fc0b889cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load = pl.read_csv(grid_load_csv,try_parse_dates=True)\n",
    "df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf6459-a124-45e3-ac15-6b1cb4eb034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = pl.read_csv(weather_csv,try_parse_dates=True)\n",
    "df_weather.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d05378d-aa33-4570-bd86-caab6548b3ee",
   "metadata": {},
   "source": [
    "- Join the weather data to the load data\n",
    "- Add a new feature with the weekday from the date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c33d074-2098-4a2a-8ba1-3c78cb2be07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid = (\n",
    "    <blank>\n",
    ")\n",
    "df_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e752b90-601b-4b80-8ad9-2f6106e62d96",
   "metadata": {},
   "source": [
    "Take data before 2020 as the training data and data in 2020 as the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d253a41-64de-4bc5-b46c-80ad227833b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "df_train = (\n",
    "    df_grid\n",
    "    .filter(pl.col(\"time\")<date(2019,4,1))\n",
    ")\n",
    "df_test = (\n",
    "    df_grid\n",
    "    .filter(pl.col(\"time\")>=date(2019,4,1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64af4db3-6c2a-4b2f-bb7b-72757ac02dbf",
   "metadata": {},
   "source": [
    "We make a list of feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa646366-b063-4528-b025-c9940ceba6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_grid.columns[2:]\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f53536-5c8d-48e6-bd47-5f8d136bf531",
   "metadata": {},
   "source": [
    "Fit the `LinearRegressor` class with an intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcaa90b-3eee-4ea0-8c54-fa28a4ed264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regressor = LinearRegressor(\n",
    "    target_col=\"load\",\n",
    "    feature_cols=features,\n",
    "    model=\"ols\",\n",
    "    add_intercept=True\n",
    ")\n",
    "linear_regressor.fit(X = df_train)\n",
    "pred_df = linear_regressor.transform(X = df_test)\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5ecf52-03ec-4d9f-b6fa-d2d8082ea0bb",
   "metadata": {},
   "source": [
    "Plot the `load` and the `pred` as line charts with `plot.line`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6d0e1a-c8d2-4368-addb-e37969554f38",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Hint\n",
    "# `unpivot` the load and pred columns with time as the index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbe075d-84e0-43e3-abcd-25cad3776f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec3e4b7f-a23f-4642-aaa7-60fa88744348",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d942d0-21dc-4d41-a25d-41fec4267e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_load_csv = \"../data/grid_load.csv\"\n",
    "weather_csv = \"../data/weather.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7af8d10-b179-444c-96b8-b4f81d325042",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load = pl.read_csv(grid_load_csv,try_parse_dates=True)\n",
    "df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f127b47f-5f7f-48cf-be73-4927309e8a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = pl.read_csv(weather_csv,try_parse_dates=True)\n",
    "df_weather.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff45841-8d06-4612-ab25-7a24f768a092",
   "metadata": {},
   "source": [
    "- Join the weather data to the load data\n",
    "- Add a new feature with the weekday from the date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc70a5-01b2-4873-9374-d12c2b84f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid = (\n",
    "    pl.read_csv(grid_load_csv ,try_parse_dates=True)\n",
    "    .join(\n",
    "        pl.read_csv(weather_csv,try_parse_dates=True),\n",
    "        on=\"time\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"time\").dt.weekday().alias(\"weekday\"),\n",
    "        pl.selectors.float().fill_null(strategy=\"mean\")\n",
    "    )\n",
    ")\n",
    "df_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c437f14-37de-4b0d-8285-87dca6a800ab",
   "metadata": {},
   "source": [
    "Take data before 2020 as the training data and data in 2020 as the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5034a13c-ac33-4e4f-90c4-fd3096af9c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "df_train = (\n",
    "    df_grid\n",
    "    .filter(pl.col(\"time\")<date(2019,4,1))\n",
    ")\n",
    "df_test = (\n",
    "    df_grid\n",
    "    .filter(pl.col(\"time\")>=date(2019,4,1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1455d49-4361-4324-be68-390d8be0098b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_grid.columns[2:]\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2417cc66-d78b-427d-a4d4-dd6195fd9513",
   "metadata": {},
   "source": [
    "Fit the `LinearRegressor` class with an intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133f004d-69a4-49b1-a070-34c1b1c34b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regressor = LinearRegressor(\n",
    "    target_col=\"load\",\n",
    "    feature_cols=features,\n",
    "    model=\"ols\",\n",
    "    add_intercept=True\n",
    ")\n",
    "linear_regressor.fit(X = df_train)\n",
    "pred_df = linear_regressor.transform(X = df_test)\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9438f71-05a0-432b-8e43-e06a0d6b1906",
   "metadata": {},
   "source": [
    "Plot the `load` and the `pred` time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87ac604-7b27-4ed9-b5fa-b63072ec9691",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pred_df\n",
    "    .unpivot(\n",
    "        index=\"time\",\n",
    "        on=[\"load\",\"pred\"]\n",
    "    )\n",
    "    .plot\n",
    "    .line(\n",
    "        x=\"time\",\n",
    "        y=\"value\",\n",
    "        color=\"variable\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f507ec-53df-42cd-8593-d062be606f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e761ad-15df-4c50-b738-f43ac1adb5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
